{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"In this assignment, you should train your own net on cifar10 classification with deep learning framework MXNet.\n",
    "   With MXNet, you only need to define the nets with symbol connection, then set hyperparameters to train the \n",
    "   network. You can also save your model and load pretrained model to finetune the network. Make sure using GPU \n",
    "   mode. You should achieve at least 80% on the validation set.\"\"\"\n",
    "\n",
    "\"\"\"vist http://mxnet.io/get_started/index.html to get familar with mxnet!\"\"\"\n",
    "#This is yaodi's notebook!   \n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import logging\n",
    "\n",
    "# download data if necessary\n",
    "def _download(data_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.system(\"mkdir \" + data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    if (not os.path.exists('train.rec')) or \\\n",
    "       (not os.path.exists('test.rec')) :\n",
    "        os.system(\"wget http://data.dmlc.ml/mxnet/data/cifar10.zip\")\n",
    "        os.system(\"unzip -u cifar10.zip\")\n",
    "        os.system(\"mv cifar/* .; rm -rf cifar; rm cifar10.zip\")\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n",
    "# data\n",
    "def get_iterator(data_shape=(3, 28, 28)):\n",
    "    if '://' not in data_dir:\n",
    "        _download(data_dir)\n",
    "\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec = os.path.join(data_dir, \"train.rec\"),\n",
    "        mean_img    = os.path.join(data_dir, \"mean.bin\"),\n",
    "        data_shape  = data_shape,\n",
    "        batch_size  = batch_size,\n",
    "        rand_crop   = True,\n",
    "        rand_mirror = True)\n",
    "\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec = os.path.join(data_dir, \"test.rec\"),\n",
    "        mean_img    = os.path.join(data_dir, \"mean.bin\"),\n",
    "        rand_crop   = False,\n",
    "        rand_mirror = False,\n",
    "        data_shape  = data_shape,\n",
    "        batch_size  = batch_size)\n",
    "\n",
    "    return (train, val)\n",
    "\n",
    "\n",
    "def get_net(num_classes=10):\n",
    "    #####################################################################################\n",
    "    # TODO: define your net                                                             #\n",
    "    # Define symbols that using convolution and max pooling to extract better features  #\n",
    "    # from input image.                                                                 #\n",
    "    #####################################################################################\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(3,3), pad=(1,1), num_filter=128)\n",
    "    bn1 = mx.symbol.BatchNorm(data=conv1)\n",
    "    relu1 = mx.symbol.Activation(data=bn1, act_type=\"relu\")\n",
    "  \n",
    "    conv2 = mx.symbol.Convolution(data=relu1, kernel=(3,3), pad=(1,1), num_filter=128)\n",
    "    bn2 = mx.symbol.BatchNorm(data=conv2)\n",
    "    relu2 = mx.symbol.Activation(data=bn2, act_type=\"relu\")\n",
    "    \n",
    "    pool1 = mx.symbol.Pooling(data=relu2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    conv3 = mx.symbol.Convolution(data=pool1, kernel=(3,3), pad=(1,1), num_filter=128)\n",
    "    bn3 = mx.symbol.BatchNorm(data=conv3)\n",
    "    relu3 = mx.symbol.Activation(data=bn3, act_type=\"relu\")\n",
    "    \n",
    "    conv4 = mx.symbol.Convolution(data=relu3, kernel=(3,3), pad=(1,1), num_filter=128)\n",
    "    bn4 = mx.symbol.BatchNorm(data=conv4)\n",
    "    relu4 = mx.symbol.Activation(data=bn4, act_type=\"relu\")\n",
    "    \n",
    "    pool2 = mx.symbol.Pooling(data=relu4, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    fc = mx.symbol.FullyConnected(data=pool2, num_hidden=1024)\n",
    "    softmax = mx.symbol.SoftmaxOutput(data=fc, name=\"softmax\")\n",
    "   \n",
    "    #####################################################################################\n",
    "    #                              END OF YOUR CODE                                     #\n",
    "    #####################################################################################\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-31 00:14:00,540 Start training with [gpu(3)]\n",
      "2016-10-31 00:14:02,705 Epoch[0] Batch [50]\tSpeed: 3582.84 samples/sec\tTrain-accuracy=0.291406\n",
      "2016-10-31 00:14:04,489 Epoch[0] Batch [100]\tSpeed: 3590.05 samples/sec\tTrain-accuracy=0.427344\n",
      "2016-10-31 00:14:06,275 Epoch[0] Batch [150]\tSpeed: 3587.45 samples/sec\tTrain-accuracy=0.479219\n",
      "2016-10-31 00:14:08,068 Epoch[0] Batch [200]\tSpeed: 3572.67 samples/sec\tTrain-accuracy=0.482656\n",
      "2016-10-31 00:14:09,859 Epoch[0] Batch [250]\tSpeed: 3575.26 samples/sec\tTrain-accuracy=0.517344\n",
      "2016-10-31 00:14:11,645 Epoch[0] Batch [300]\tSpeed: 3586.10 samples/sec\tTrain-accuracy=0.541875\n",
      "2016-10-31 00:14:13,440 Epoch[0] Batch [350]\tSpeed: 3568.62 samples/sec\tTrain-accuracy=0.568750\n",
      "2016-10-31 00:14:14,915 Epoch[0] Resetting Data Iterator\n",
      "2016-10-31 00:14:14,917 Epoch[0] Time cost=14.222\n",
      "2016-10-31 00:14:16,034 Epoch[0] Validation-accuracy=0.600969\n",
      "2016-10-31 00:14:17,805 Epoch[1] Batch [50]\tSpeed: 3651.35 samples/sec\tTrain-accuracy=0.585625\n",
      "2016-10-31 00:14:19,600 Epoch[1] Batch [100]\tSpeed: 3567.84 samples/sec\tTrain-accuracy=0.606250\n",
      "2016-10-31 00:14:21,389 Epoch[1] Batch [150]\tSpeed: 3580.85 samples/sec\tTrain-accuracy=0.621875\n",
      "2016-10-31 00:14:23,190 Epoch[1] Batch [200]\tSpeed: 3554.87 samples/sec\tTrain-accuracy=0.634062\n",
      "2016-10-31 00:14:24,992 Epoch[1] Batch [250]\tSpeed: 3555.06 samples/sec\tTrain-accuracy=0.648594\n",
      "2016-10-31 00:14:26,788 Epoch[1] Batch [300]\tSpeed: 3565.53 samples/sec\tTrain-accuracy=0.648281\n",
      "2016-10-31 00:14:28,585 Epoch[1] Batch [350]\tSpeed: 3564.40 samples/sec\tTrain-accuracy=0.648906\n",
      "2016-10-31 00:14:30,060 Epoch[1] Resetting Data Iterator\n",
      "2016-10-31 00:14:30,062 Epoch[1] Time cost=14.027\n",
      "2016-10-31 00:14:31,162 Epoch[1] Validation-accuracy=0.679193\n",
      "2016-10-31 00:14:32,952 Epoch[2] Batch [50]\tSpeed: 3615.33 samples/sec\tTrain-accuracy=0.669844\n",
      "2016-10-31 00:14:34,755 Epoch[2] Batch [100]\tSpeed: 3552.83 samples/sec\tTrain-accuracy=0.675156\n",
      "2016-10-31 00:14:36,568 Epoch[2] Batch [150]\tSpeed: 3531.39 samples/sec\tTrain-accuracy=0.680937\n",
      "2016-10-31 00:14:38,389 Epoch[2] Batch [200]\tSpeed: 3516.74 samples/sec\tTrain-accuracy=0.695625\n",
      "2016-10-31 00:14:40,199 Epoch[2] Batch [250]\tSpeed: 3538.92 samples/sec\tTrain-accuracy=0.692344\n",
      "2016-10-31 00:14:42,014 Epoch[2] Batch [300]\tSpeed: 3528.41 samples/sec\tTrain-accuracy=0.696406\n",
      "2016-10-31 00:14:43,828 Epoch[2] Batch [350]\tSpeed: 3531.79 samples/sec\tTrain-accuracy=0.685937\n",
      "2016-10-31 00:14:45,280 Epoch[2] Resetting Data Iterator\n",
      "2016-10-31 00:14:45,282 Epoch[2] Time cost=14.119\n",
      "2016-10-31 00:14:46,378 Epoch[2] Validation-accuracy=0.684632\n",
      "2016-10-31 00:14:48,171 Epoch[3] Batch [50]\tSpeed: 3606.55 samples/sec\tTrain-accuracy=0.708906\n",
      "2016-10-31 00:14:49,989 Epoch[3] Batch [100]\tSpeed: 3521.94 samples/sec\tTrain-accuracy=0.701406\n",
      "2016-10-31 00:14:51,803 Epoch[3] Batch [150]\tSpeed: 3530.93 samples/sec\tTrain-accuracy=0.721719\n",
      "2016-10-31 00:14:53,633 Epoch[3] Batch [200]\tSpeed: 3500.28 samples/sec\tTrain-accuracy=0.718281\n",
      "2016-10-31 00:14:55,463 Epoch[3] Batch [250]\tSpeed: 3499.60 samples/sec\tTrain-accuracy=0.718906\n",
      "2016-10-31 00:14:57,287 Epoch[3] Batch [300]\tSpeed: 3510.45 samples/sec\tTrain-accuracy=0.718594\n",
      "2016-10-31 00:14:59,125 Epoch[3] Batch [350]\tSpeed: 3484.81 samples/sec\tTrain-accuracy=0.722969\n",
      "2016-10-31 00:15:00,625 Epoch[3] Resetting Data Iterator\n",
      "2016-10-31 00:15:00,626 Epoch[3] Time cost=14.247\n",
      "2016-10-31 00:15:01,768 Epoch[3] Validation-accuracy=0.726661\n",
      "2016-10-31 00:15:03,587 Epoch[4] Batch [50]\tSpeed: 3557.11 samples/sec\tTrain-accuracy=0.729531\n",
      "2016-10-31 00:15:05,413 Epoch[4] Batch [100]\tSpeed: 3508.68 samples/sec\tTrain-accuracy=0.732500\n",
      "2016-10-31 00:15:07,238 Epoch[4] Batch [150]\tSpeed: 3508.54 samples/sec\tTrain-accuracy=0.735000\n",
      "2016-10-31 00:15:09,066 Epoch[4] Batch [200]\tSpeed: 3503.54 samples/sec\tTrain-accuracy=0.737187\n",
      "2016-10-31 00:15:10,900 Epoch[4] Batch [250]\tSpeed: 3493.16 samples/sec\tTrain-accuracy=0.737187\n",
      "2016-10-31 00:15:12,767 Epoch[4] Batch [300]\tSpeed: 3428.91 samples/sec\tTrain-accuracy=0.741875\n",
      "2016-10-31 00:15:14,763 Epoch[4] Batch [350]\tSpeed: 3211.02 samples/sec\tTrain-accuracy=0.743281\n",
      "2016-10-31 00:15:16,423 Epoch[4] Resetting Data Iterator\n",
      "2016-10-31 00:15:16,425 Epoch[4] Time cost=14.654\n",
      "2016-10-31 00:15:17,643 Epoch[4] Validation-accuracy=0.725870\n",
      "2016-10-31 00:15:19,597 Epoch[5] Batch [50]\tSpeed: 3305.78 samples/sec\tTrain-accuracy=0.750469\n",
      "2016-10-31 00:15:21,569 Epoch[5] Batch [100]\tSpeed: 3246.13 samples/sec\tTrain-accuracy=0.747500\n",
      "2016-10-31 00:15:23,540 Epoch[5] Batch [150]\tSpeed: 3248.58 samples/sec\tTrain-accuracy=0.758125\n",
      "2016-10-31 00:15:25,519 Epoch[5] Batch [200]\tSpeed: 3235.97 samples/sec\tTrain-accuracy=0.758437\n",
      "2016-10-31 00:15:27,481 Epoch[5] Batch [250]\tSpeed: 3265.27 samples/sec\tTrain-accuracy=0.760156\n",
      "2016-10-31 00:15:29,420 Epoch[5] Batch [300]\tSpeed: 3302.97 samples/sec\tTrain-accuracy=0.766094\n",
      "2016-10-31 00:15:31,359 Epoch[5] Batch [350]\tSpeed: 3302.62 samples/sec\tTrain-accuracy=0.755000\n",
      "2016-10-31 00:15:32,907 Epoch[5] Resetting Data Iterator\n",
      "2016-10-31 00:15:32,908 Epoch[5] Time cost=15.263\n",
      "2016-10-31 00:15:34,067 Epoch[5] Validation-accuracy=0.740902\n",
      "2016-10-31 00:15:35,942 Epoch[6] Batch [50]\tSpeed: 3449.42 samples/sec\tTrain-accuracy=0.766406\n",
      "2016-10-31 00:15:37,839 Epoch[6] Batch [100]\tSpeed: 3376.68 samples/sec\tTrain-accuracy=0.764219\n",
      "2016-10-31 00:15:39,736 Epoch[6] Batch [150]\tSpeed: 3374.04 samples/sec\tTrain-accuracy=0.777656\n",
      "2016-10-31 00:15:41,648 Epoch[6] Batch [200]\tSpeed: 3352.02 samples/sec\tTrain-accuracy=0.773125\n",
      "2016-10-31 00:15:43,583 Epoch[6] Batch [250]\tSpeed: 3309.94 samples/sec\tTrain-accuracy=0.771563\n",
      "2016-10-31 00:15:45,519 Epoch[6] Batch [300]\tSpeed: 3306.78 samples/sec\tTrain-accuracy=0.766563\n",
      "2016-10-31 00:15:47,449 Epoch[6] Batch [350]\tSpeed: 3318.27 samples/sec\tTrain-accuracy=0.780781\n",
      "2016-10-31 00:15:49,043 Epoch[6] Resetting Data Iterator\n",
      "2016-10-31 00:15:49,044 Epoch[6] Time cost=14.976\n",
      "2016-10-31 00:15:50,236 Epoch[6] Validation-accuracy=0.749802\n",
      "2016-10-31 00:15:52,111 Epoch[7] Batch [50]\tSpeed: 3457.69 samples/sec\tTrain-accuracy=0.778750\n",
      "2016-10-31 00:15:54,006 Epoch[7] Batch [100]\tSpeed: 3378.82 samples/sec\tTrain-accuracy=0.779219\n",
      "2016-10-31 00:15:55,930 Epoch[7] Batch [150]\tSpeed: 3329.78 samples/sec\tTrain-accuracy=0.790312\n",
      "2016-10-31 00:15:57,865 Epoch[7] Batch [200]\tSpeed: 3309.33 samples/sec\tTrain-accuracy=0.785000\n",
      "2016-10-31 00:15:59,817 Epoch[7] Batch [250]\tSpeed: 3281.16 samples/sec\tTrain-accuracy=0.787031\n",
      "2016-10-31 00:16:01,759 Epoch[7] Batch [300]\tSpeed: 3296.78 samples/sec\tTrain-accuracy=0.786875\n",
      "2016-10-31 00:16:03,704 Epoch[7] Batch [350]\tSpeed: 3292.83 samples/sec\tTrain-accuracy=0.783281\n",
      "2016-10-31 00:16:05,270 Epoch[7] Resetting Data Iterator\n",
      "2016-10-31 00:16:05,272 Epoch[7] Time cost=15.035\n",
      "2016-10-31 00:16:06,517 Epoch[7] Validation-accuracy=0.760977\n",
      "2016-10-31 00:16:08,428 Epoch[8] Batch [50]\tSpeed: 3385.38 samples/sec\tTrain-accuracy=0.794375\n",
      "2016-10-31 00:16:10,351 Epoch[8] Batch [100]\tSpeed: 3328.27 samples/sec\tTrain-accuracy=0.791719\n",
      "2016-10-31 00:16:12,286 Epoch[8] Batch [150]\tSpeed: 3310.63 samples/sec\tTrain-accuracy=0.804063\n",
      "2016-10-31 00:16:14,224 Epoch[8] Batch [200]\tSpeed: 3303.86 samples/sec\tTrain-accuracy=0.797813\n",
      "2016-10-31 00:16:16,165 Epoch[8] Batch [250]\tSpeed: 3300.73 samples/sec\tTrain-accuracy=0.800000\n",
      "2016-10-31 00:16:18,105 Epoch[8] Batch [300]\tSpeed: 3301.17 samples/sec\tTrain-accuracy=0.795000\n",
      "2016-10-31 00:16:20,051 Epoch[8] Batch [350]\tSpeed: 3292.43 samples/sec\tTrain-accuracy=0.797500\n",
      "2016-10-31 00:16:21,646 Epoch[8] Resetting Data Iterator\n",
      "2016-10-31 00:16:21,647 Epoch[8] Time cost=15.129\n",
      "2016-10-31 00:16:22,837 Epoch[8] Validation-accuracy=0.765724\n",
      "2016-10-31 00:16:24,751 Epoch[9] Batch [50]\tSpeed: 3377.55 samples/sec\tTrain-accuracy=0.795937\n",
      "2016-10-31 00:16:26,693 Epoch[9] Batch [100]\tSpeed: 3296.13 samples/sec\tTrain-accuracy=0.804219\n",
      "2016-10-31 00:16:28,630 Epoch[9] Batch [150]\tSpeed: 3307.32 samples/sec\tTrain-accuracy=0.808438\n",
      "2016-10-31 00:16:30,571 Epoch[9] Batch [200]\tSpeed: 3299.62 samples/sec\tTrain-accuracy=0.799063\n",
      "2016-10-31 00:16:32,525 Epoch[9] Batch [250]\tSpeed: 3276.27 samples/sec\tTrain-accuracy=0.804375\n",
      "2016-10-31 00:16:34,488 Epoch[9] Batch [300]\tSpeed: 3263.16 samples/sec\tTrain-accuracy=0.800156\n",
      "2016-10-31 00:16:36,450 Epoch[9] Batch [350]\tSpeed: 3263.46 samples/sec\tTrain-accuracy=0.810312\n",
      "2016-10-31 00:16:38,064 Epoch[9] Resetting Data Iterator\n",
      "2016-10-31 00:16:38,072 Epoch[9] Time cost=15.234\n",
      "2016-10-31 00:16:38,147 Saved checkpoint to \"model/net1-0010.params\"\n",
      "2016-10-31 00:16:39,296 Epoch[9] Validation-accuracy=0.776800\n",
      "2016-10-31 00:16:41,195 Epoch[10] Batch [50]\tSpeed: 3405.76 samples/sec\tTrain-accuracy=0.810469\n",
      "2016-10-31 00:16:43,124 Epoch[10] Batch [100]\tSpeed: 3319.96 samples/sec\tTrain-accuracy=0.802656\n",
      "2016-10-31 00:16:45,070 Epoch[10] Batch [150]\tSpeed: 3291.15 samples/sec\tTrain-accuracy=0.815781\n",
      "2016-10-31 00:16:47,034 Epoch[10] Batch [200]\tSpeed: 3260.57 samples/sec\tTrain-accuracy=0.807031\n",
      "2016-10-31 00:16:49,000 Epoch[10] Batch [250]\tSpeed: 3258.13 samples/sec\tTrain-accuracy=0.816094\n",
      "2016-10-31 00:16:50,961 Epoch[10] Batch [300]\tSpeed: 3265.10 samples/sec\tTrain-accuracy=0.821562\n",
      "2016-10-31 00:16:52,923 Epoch[10] Batch [350]\tSpeed: 3264.62 samples/sec\tTrain-accuracy=0.815312\n",
      "2016-10-31 00:16:54,495 Epoch[10] Resetting Data Iterator\n",
      "2016-10-31 00:16:54,497 Epoch[10] Time cost=15.200\n",
      "2016-10-31 00:16:55,652 Epoch[10] Validation-accuracy=0.797567\n",
      "2016-10-31 00:16:57,565 Epoch[11] Batch [50]\tSpeed: 3378.29 samples/sec\tTrain-accuracy=0.820625\n",
      "2016-10-31 00:16:59,498 Epoch[11] Batch [100]\tSpeed: 3313.57 samples/sec\tTrain-accuracy=0.817969\n",
      "2016-10-31 00:17:01,434 Epoch[11] Batch [150]\tSpeed: 3307.66 samples/sec\tTrain-accuracy=0.830156\n",
      "2016-10-31 00:17:03,385 Epoch[11] Batch [200]\tSpeed: 3281.42 samples/sec\tTrain-accuracy=0.818125\n",
      "2016-10-31 00:17:05,327 Epoch[11] Batch [250]\tSpeed: 3298.22 samples/sec\tTrain-accuracy=0.822969\n",
      "2016-10-31 00:17:07,266 Epoch[11] Batch [300]\tSpeed: 3303.77 samples/sec\tTrain-accuracy=0.822344\n",
      "2016-10-31 00:17:09,204 Epoch[11] Batch [350]\tSpeed: 3305.02 samples/sec\tTrain-accuracy=0.823125\n",
      "2016-10-31 00:17:10,813 Epoch[11] Resetting Data Iterator\n",
      "2016-10-31 00:17:10,818 Epoch[11] Time cost=15.166\n",
      "2016-10-31 00:17:12,042 Epoch[11] Validation-accuracy=0.760977\n",
      "2016-10-31 00:17:13,971 Epoch[12] Batch [50]\tSpeed: 3353.60 samples/sec\tTrain-accuracy=0.819531\n",
      "2016-10-31 00:17:15,909 Epoch[12] Batch [100]\tSpeed: 3304.91 samples/sec\tTrain-accuracy=0.823906\n",
      "2016-10-31 00:17:17,848 Epoch[12] Batch [150]\tSpeed: 3303.68 samples/sec\tTrain-accuracy=0.830781\n",
      "2016-10-31 00:17:19,792 Epoch[12] Batch [200]\tSpeed: 3296.03 samples/sec\tTrain-accuracy=0.822187\n",
      "2016-10-31 00:17:21,740 Epoch[12] Batch [250]\tSpeed: 3287.98 samples/sec\tTrain-accuracy=0.826875\n",
      "2016-10-31 00:17:23,689 Epoch[12] Batch [300]\tSpeed: 3285.60 samples/sec\tTrain-accuracy=0.826562\n",
      "2016-10-31 00:17:25,647 Epoch[12] Batch [350]\tSpeed: 3271.80 samples/sec\tTrain-accuracy=0.830937\n",
      "2016-10-31 00:17:27,253 Epoch[12] Resetting Data Iterator\n",
      "2016-10-31 00:17:27,255 Epoch[12] Time cost=15.211\n",
      "2016-10-31 00:17:28,427 Epoch[12] Validation-accuracy=0.812104\n",
      "2016-10-31 00:17:30,348 Epoch[13] Batch [50]\tSpeed: 3366.08 samples/sec\tTrain-accuracy=0.824063\n",
      "2016-10-31 00:17:32,288 Epoch[13] Batch [100]\tSpeed: 3300.12 samples/sec\tTrain-accuracy=0.826250\n",
      "2016-10-31 00:17:34,224 Epoch[13] Batch [150]\tSpeed: 3308.18 samples/sec\tTrain-accuracy=0.847187\n",
      "2016-10-31 00:17:36,179 Epoch[13] Batch [200]\tSpeed: 3277.09 samples/sec\tTrain-accuracy=0.831406\n",
      "2016-10-31 00:17:38,151 Epoch[13] Batch [250]\tSpeed: 3247.44 samples/sec\tTrain-accuracy=0.835156\n",
      "2016-10-31 00:17:40,113 Epoch[13] Batch [300]\tSpeed: 3263.02 samples/sec\tTrain-accuracy=0.831719\n",
      "2016-10-31 00:17:42,079 Epoch[13] Batch [350]\tSpeed: 3258.57 samples/sec\tTrain-accuracy=0.836562\n",
      "2016-10-31 00:17:43,651 Epoch[13] Resetting Data Iterator\n",
      "2016-10-31 00:17:43,653 Epoch[13] Time cost=15.224\n",
      "2016-10-31 00:17:44,899 Epoch[13] Validation-accuracy=0.797172\n",
      "2016-10-31 00:17:46,813 Epoch[14] Batch [50]\tSpeed: 3378.30 samples/sec\tTrain-accuracy=0.843750\n",
      "2016-10-31 00:17:48,743 Epoch[14] Batch [100]\tSpeed: 3317.85 samples/sec\tTrain-accuracy=0.840781\n",
      "2016-10-31 00:17:50,692 Epoch[14] Batch [150]\tSpeed: 3287.24 samples/sec\tTrain-accuracy=0.843750\n",
      "2016-10-31 00:17:52,629 Epoch[14] Batch [200]\tSpeed: 3306.21 samples/sec\tTrain-accuracy=0.837344\n",
      "2016-10-31 00:17:54,578 Epoch[14] Batch [250]\tSpeed: 3284.98 samples/sec\tTrain-accuracy=0.833594\n",
      "2016-10-31 00:17:56,539 Epoch[14] Batch [300]\tSpeed: 3266.40 samples/sec\tTrain-accuracy=0.837031\n",
      "2016-10-31 00:17:58,504 Epoch[14] Batch [350]\tSpeed: 3258.70 samples/sec\tTrain-accuracy=0.838594\n",
      "2016-10-31 00:18:00,122 Epoch[14] Resetting Data Iterator\n",
      "2016-10-31 00:18:00,124 Epoch[14] Time cost=15.223\n",
      "2016-10-31 00:18:01,352 Epoch[14] Validation-accuracy=0.808643\n",
      "2016-10-31 00:18:03,269 Epoch[15] Batch [50]\tSpeed: 3374.29 samples/sec\tTrain-accuracy=0.847500\n",
      "2016-10-31 00:18:05,206 Epoch[15] Batch [100]\tSpeed: 3306.92 samples/sec\tTrain-accuracy=0.840938\n",
      "2016-10-31 00:18:07,134 Epoch[15] Batch [150]\tSpeed: 3323.21 samples/sec\tTrain-accuracy=0.853437\n",
      "2016-10-31 00:18:09,073 Epoch[15] Batch [200]\tSpeed: 3301.22 samples/sec\tTrain-accuracy=0.842344\n",
      "2016-10-31 00:18:11,030 Epoch[15] Batch [250]\tSpeed: 3273.98 samples/sec\tTrain-accuracy=0.841562\n",
      "2016-10-31 00:18:12,991 Epoch[15] Batch [300]\tSpeed: 3266.03 samples/sec\tTrain-accuracy=0.847344\n",
      "2016-10-31 00:18:14,958 Epoch[15] Batch [350]\tSpeed: 3255.88 samples/sec\tTrain-accuracy=0.845469\n",
      "2016-10-31 00:18:16,536 Epoch[15] Resetting Data Iterator\n",
      "2016-10-31 00:18:16,538 Epoch[15] Time cost=15.184\n",
      "2016-10-31 00:18:17,757 Epoch[15] Validation-accuracy=0.799941\n",
      "2016-10-31 00:18:19,680 Epoch[16] Batch [50]\tSpeed: 3360.90 samples/sec\tTrain-accuracy=0.850156\n",
      "2016-10-31 00:18:21,615 Epoch[16] Batch [100]\tSpeed: 3310.00 samples/sec\tTrain-accuracy=0.850156\n",
      "2016-10-31 00:18:23,545 Epoch[16] Batch [150]\tSpeed: 3320.05 samples/sec\tTrain-accuracy=0.857500\n",
      "2016-10-31 00:18:25,480 Epoch[16] Batch [200]\tSpeed: 3309.59 samples/sec\tTrain-accuracy=0.845625\n",
      "2016-10-31 00:18:27,422 Epoch[16] Batch [250]\tSpeed: 3298.00 samples/sec\tTrain-accuracy=0.844531\n",
      "2016-10-31 00:18:29,358 Epoch[16] Batch [300]\tSpeed: 3307.89 samples/sec\tTrain-accuracy=0.848906\n",
      "2016-10-31 00:18:31,302 Epoch[16] Batch [350]\tSpeed: 3294.78 samples/sec\tTrain-accuracy=0.852344\n",
      "2016-10-31 00:18:32,912 Epoch[16] Resetting Data Iterator\n",
      "2016-10-31 00:18:32,914 Epoch[16] Time cost=15.156\n",
      "2016-10-31 00:18:34,066 Epoch[16] Validation-accuracy=0.818236\n",
      "2016-10-31 00:18:35,972 Epoch[17] Batch [50]\tSpeed: 3386.88 samples/sec\tTrain-accuracy=0.852187\n",
      "2016-10-31 00:18:37,903 Epoch[17] Batch [100]\tSpeed: 3316.82 samples/sec\tTrain-accuracy=0.849063\n",
      "2016-10-31 00:18:39,851 Epoch[17] Batch [150]\tSpeed: 3286.36 samples/sec\tTrain-accuracy=0.859219\n",
      "2016-10-31 00:18:41,794 Epoch[17] Batch [200]\tSpeed: 3297.96 samples/sec\tTrain-accuracy=0.848281\n",
      "2016-10-31 00:18:43,734 Epoch[17] Batch [250]\tSpeed: 3301.29 samples/sec\tTrain-accuracy=0.852812\n",
      "2016-10-31 00:18:45,686 Epoch[17] Batch [300]\tSpeed: 3281.53 samples/sec\tTrain-accuracy=0.863594\n",
      "2016-10-31 00:18:47,638 Epoch[17] Batch [350]\tSpeed: 3281.72 samples/sec\tTrain-accuracy=0.857031\n",
      "2016-10-31 00:18:49,257 Epoch[17] Resetting Data Iterator\n",
      "2016-10-31 00:18:49,258 Epoch[17] Time cost=15.192\n",
      "2016-10-31 00:18:50,428 Epoch[17] Validation-accuracy=0.821697\n",
      "2016-10-31 00:18:52,351 Epoch[18] Batch [50]\tSpeed: 3361.73 samples/sec\tTrain-accuracy=0.854531\n",
      "2016-10-31 00:18:54,313 Epoch[18] Batch [100]\tSpeed: 3264.12 samples/sec\tTrain-accuracy=0.858125\n",
      "2016-10-31 00:18:56,260 Epoch[18] Batch [150]\tSpeed: 3291.65 samples/sec\tTrain-accuracy=0.865625\n",
      "2016-10-31 00:18:58,205 Epoch[18] Batch [200]\tSpeed: 3291.62 samples/sec\tTrain-accuracy=0.858125\n",
      "2016-10-31 00:19:00,149 Epoch[18] Batch [250]\tSpeed: 3294.64 samples/sec\tTrain-accuracy=0.860781\n",
      "2016-10-31 00:19:02,093 Epoch[18] Batch [300]\tSpeed: 3294.72 samples/sec\tTrain-accuracy=0.860469\n",
      "2016-10-31 00:19:04,047 Epoch[18] Batch [350]\tSpeed: 3277.87 samples/sec\tTrain-accuracy=0.861719\n",
      "2016-10-31 00:19:05,601 Epoch[18] Resetting Data Iterator\n",
      "2016-10-31 00:19:05,617 Epoch[18] Time cost=15.189\n",
      "2016-10-31 00:19:06,763 Epoch[18] Validation-accuracy=0.807951\n",
      "2016-10-31 00:19:08,656 Epoch[19] Batch [50]\tSpeed: 3410.51 samples/sec\tTrain-accuracy=0.861719\n",
      "2016-10-31 00:19:10,589 Epoch[19] Batch [100]\tSpeed: 3312.43 samples/sec\tTrain-accuracy=0.861875\n",
      "2016-10-31 00:19:12,527 Epoch[19] Batch [150]\tSpeed: 3304.96 samples/sec\tTrain-accuracy=0.861250\n",
      "2016-10-31 00:19:14,473 Epoch[19] Batch [200]\tSpeed: 3289.46 samples/sec\tTrain-accuracy=0.857500\n",
      "2016-10-31 00:19:16,417 Epoch[19] Batch [250]\tSpeed: 3295.52 samples/sec\tTrain-accuracy=0.859375\n",
      "2016-10-31 00:19:18,377 Epoch[19] Batch [300]\tSpeed: 3267.50 samples/sec\tTrain-accuracy=0.864688\n",
      "2016-10-31 00:19:20,343 Epoch[19] Batch [350]\tSpeed: 3257.54 samples/sec\tTrain-accuracy=0.866719\n",
      "2016-10-31 00:19:21,950 Epoch[19] Resetting Data Iterator\n",
      "2016-10-31 00:19:21,951 Epoch[19] Time cost=15.187\n",
      "2016-10-31 00:19:22,025 Saved checkpoint to \"model/net1-0020.params\"\n",
      "2016-10-31 00:19:23,178 Epoch[19] Validation-accuracy=0.819324\n",
      "2016-10-31 00:19:25,083 Epoch[20] Batch [50]\tSpeed: 3395.13 samples/sec\tTrain-accuracy=0.867031\n",
      "2016-10-31 00:19:26,996 Epoch[20] Batch [100]\tSpeed: 3349.70 samples/sec\tTrain-accuracy=0.862656\n",
      "2016-10-31 00:19:28,919 Epoch[20] Batch [150]\tSpeed: 3329.58 samples/sec\tTrain-accuracy=0.875313\n",
      "2016-10-31 00:19:30,876 Epoch[20] Batch [200]\tSpeed: 3271.67 samples/sec\tTrain-accuracy=0.866406\n",
      "2016-10-31 00:19:32,843 Epoch[20] Batch [250]\tSpeed: 3257.20 samples/sec\tTrain-accuracy=0.868437\n",
      "2016-10-31 00:19:34,806 Epoch[20] Batch [300]\tSpeed: 3262.79 samples/sec\tTrain-accuracy=0.869687\n",
      "2016-10-31 00:19:36,774 Epoch[20] Batch [350]\tSpeed: 3254.15 samples/sec\tTrain-accuracy=0.872500\n",
      "2016-10-31 00:19:38,388 Epoch[20] Resetting Data Iterator\n",
      "2016-10-31 00:19:38,389 Epoch[20] Time cost=15.210\n",
      "2016-10-31 00:19:39,569 Epoch[20] Validation-accuracy=0.815665\n",
      "2016-10-31 00:19:41,477 Epoch[21] Batch [50]\tSpeed: 3388.39 samples/sec\tTrain-accuracy=0.871406\n",
      "2016-10-31 00:19:43,409 Epoch[21] Batch [100]\tSpeed: 3315.77 samples/sec\tTrain-accuracy=0.872969\n",
      "2016-10-31 00:19:45,323 Epoch[21] Batch [150]\tSpeed: 3346.00 samples/sec\tTrain-accuracy=0.874062\n",
      "2016-10-31 00:19:47,255 Epoch[21] Batch [200]\tSpeed: 3316.15 samples/sec\tTrain-accuracy=0.868906\n",
      "2016-10-31 00:19:49,207 Epoch[21] Batch [250]\tSpeed: 3279.93 samples/sec\tTrain-accuracy=0.872344\n",
      "2016-10-31 00:19:51,150 Epoch[21] Batch [300]\tSpeed: 3298.39 samples/sec\tTrain-accuracy=0.873125\n",
      "2016-10-31 00:19:53,090 Epoch[21] Batch [350]\tSpeed: 3300.40 samples/sec\tTrain-accuracy=0.875938\n",
      "2016-10-31 00:19:54,646 Epoch[21] Resetting Data Iterator\n",
      "2016-10-31 00:19:54,648 Epoch[21] Time cost=15.077\n",
      "2016-10-31 00:19:55,852 Epoch[21] Validation-accuracy=0.828323\n",
      "2016-10-31 00:19:57,746 Epoch[22] Batch [50]\tSpeed: 3411.58 samples/sec\tTrain-accuracy=0.877344\n",
      "2016-10-31 00:19:59,675 Epoch[22] Batch [100]\tSpeed: 3321.14 samples/sec\tTrain-accuracy=0.876719\n",
      "2016-10-31 00:20:01,615 Epoch[22] Batch [150]\tSpeed: 3300.80 samples/sec\tTrain-accuracy=0.881094\n",
      "2016-10-31 00:20:03,557 Epoch[22] Batch [200]\tSpeed: 3299.46 samples/sec\tTrain-accuracy=0.877656\n",
      "2016-10-31 00:20:05,499 Epoch[22] Batch [250]\tSpeed: 3298.30 samples/sec\tTrain-accuracy=0.872188\n",
      "2016-10-31 00:20:07,441 Epoch[22] Batch [300]\tSpeed: 3296.55 samples/sec\tTrain-accuracy=0.874062\n",
      "2016-10-31 00:20:09,387 Epoch[22] Batch [350]\tSpeed: 3291.36 samples/sec\tTrain-accuracy=0.880000\n",
      "2016-10-31 00:20:10,982 Epoch[22] Resetting Data Iterator\n",
      "2016-10-31 00:20:10,986 Epoch[22] Time cost=15.134\n",
      "2016-10-31 00:20:12,149 Epoch[22] Validation-accuracy=0.836630\n",
      "2016-10-31 00:20:14,045 Epoch[23] Batch [50]\tSpeed: 3405.41 samples/sec\tTrain-accuracy=0.880000\n",
      "2016-10-31 00:20:15,967 Epoch[23] Batch [100]\tSpeed: 3331.59 samples/sec\tTrain-accuracy=0.879531\n",
      "2016-10-31 00:20:17,898 Epoch[23] Batch [150]\tSpeed: 3317.33 samples/sec\tTrain-accuracy=0.878281\n",
      "2016-10-31 00:20:19,830 Epoch[23] Batch [200]\tSpeed: 3314.13 samples/sec\tTrain-accuracy=0.876406\n",
      "2016-10-31 00:20:21,779 Epoch[23] Batch [250]\tSpeed: 3287.83 samples/sec\tTrain-accuracy=0.874844\n",
      "2016-10-31 00:20:23,731 Epoch[23] Batch [300]\tSpeed: 3281.45 samples/sec\tTrain-accuracy=0.870313\n",
      "2016-10-31 00:20:25,675 Epoch[23] Batch [350]\tSpeed: 3294.38 samples/sec\tTrain-accuracy=0.879375\n",
      "2016-10-31 00:20:27,238 Epoch[23] Resetting Data Iterator\n",
      "2016-10-31 00:20:27,240 Epoch[23] Time cost=15.090\n",
      "2016-10-31 00:20:28,472 Epoch[23] Validation-accuracy=0.834652\n",
      "2016-10-31 00:20:30,366 Epoch[24] Batch [50]\tSpeed: 3414.21 samples/sec\tTrain-accuracy=0.880625\n",
      "2016-10-31 00:20:32,291 Epoch[24] Batch [100]\tSpeed: 3326.45 samples/sec\tTrain-accuracy=0.878750\n",
      "2016-10-31 00:20:34,226 Epoch[24] Batch [150]\tSpeed: 3310.70 samples/sec\tTrain-accuracy=0.884687\n",
      "2016-10-31 00:20:36,165 Epoch[24] Batch [200]\tSpeed: 3304.23 samples/sec\tTrain-accuracy=0.880625\n",
      "2016-10-31 00:20:38,101 Epoch[24] Batch [250]\tSpeed: 3308.47 samples/sec\tTrain-accuracy=0.876875\n",
      "2016-10-31 00:20:40,049 Epoch[24] Batch [300]\tSpeed: 3286.75 samples/sec\tTrain-accuracy=0.879375\n",
      "2016-10-31 00:20:41,988 Epoch[24] Batch [350]\tSpeed: 3304.46 samples/sec\tTrain-accuracy=0.881250\n",
      "2016-10-31 00:20:43,587 Epoch[24] Resetting Data Iterator\n",
      "2016-10-31 00:20:43,588 Epoch[24] Time cost=15.115\n",
      "2016-10-31 00:20:44,737 Epoch[24] Validation-accuracy=0.817840\n",
      "2016-10-31 00:20:46,631 Epoch[25] Batch [50]\tSpeed: 3414.76 samples/sec\tTrain-accuracy=0.886250\n",
      "2016-10-31 00:20:48,559 Epoch[25] Batch [100]\tSpeed: 3321.62 samples/sec\tTrain-accuracy=0.883906\n",
      "2016-10-31 00:20:50,490 Epoch[25] Batch [150]\tSpeed: 3316.70 samples/sec\tTrain-accuracy=0.891094\n",
      "2016-10-31 00:20:52,421 Epoch[25] Batch [200]\tSpeed: 3317.42 samples/sec\tTrain-accuracy=0.879687\n",
      "2016-10-31 00:20:54,361 Epoch[25] Batch [250]\tSpeed: 3301.16 samples/sec\tTrain-accuracy=0.884062\n",
      "2016-10-31 00:20:56,323 Epoch[25] Batch [300]\tSpeed: 3263.73 samples/sec\tTrain-accuracy=0.873437\n",
      "2016-10-31 00:20:58,280 Epoch[25] Batch [350]\tSpeed: 3273.60 samples/sec\tTrain-accuracy=0.881250\n",
      "2016-10-31 00:20:59,886 Epoch[25] Resetting Data Iterator\n",
      "2016-10-31 00:20:59,887 Epoch[25] Time cost=15.148\n",
      "2016-10-31 00:21:01,081 Epoch[25] Validation-accuracy=0.841673\n",
      "2016-10-31 00:21:02,970 Epoch[26] Batch [50]\tSpeed: 3423.43 samples/sec\tTrain-accuracy=0.885625\n",
      "2016-10-31 00:21:04,882 Epoch[26] Batch [100]\tSpeed: 3350.25 samples/sec\tTrain-accuracy=0.884219\n",
      "2016-10-31 00:21:06,797 Epoch[26] Batch [150]\tSpeed: 3343.67 samples/sec\tTrain-accuracy=0.888906\n",
      "2016-10-31 00:21:08,720 Epoch[26] Batch [200]\tSpeed: 3330.12 samples/sec\tTrain-accuracy=0.886719\n",
      "2016-10-31 00:21:10,645 Epoch[26] Batch [250]\tSpeed: 3328.55 samples/sec\tTrain-accuracy=0.886250\n",
      "2016-10-31 00:21:12,572 Epoch[26] Batch [300]\tSpeed: 3322.02 samples/sec\tTrain-accuracy=0.888281\n",
      "2016-10-31 00:21:14,504 Epoch[26] Batch [350]\tSpeed: 3316.48 samples/sec\tTrain-accuracy=0.890469\n",
      "2016-10-31 00:21:16,055 Epoch[26] Resetting Data Iterator\n",
      "2016-10-31 00:21:16,056 Epoch[26] Time cost=14.974\n",
      "2016-10-31 00:21:17,213 Epoch[26] Validation-accuracy=0.835839\n",
      "2016-10-31 00:21:19,123 Epoch[27] Batch [50]\tSpeed: 3385.92 samples/sec\tTrain-accuracy=0.893437\n",
      "2016-10-31 00:21:21,057 Epoch[27] Batch [100]\tSpeed: 3310.45 samples/sec\tTrain-accuracy=0.884219\n",
      "2016-10-31 00:21:22,983 Epoch[27] Batch [150]\tSpeed: 3326.59 samples/sec\tTrain-accuracy=0.894687\n",
      "2016-10-31 00:21:24,940 Epoch[27] Batch [200]\tSpeed: 3271.06 samples/sec\tTrain-accuracy=0.888594\n",
      "2016-10-31 00:21:26,872 Epoch[27] Batch [250]\tSpeed: 3315.92 samples/sec\tTrain-accuracy=0.886563\n",
      "2016-10-31 00:21:28,806 Epoch[27] Batch [300]\tSpeed: 3309.97 samples/sec\tTrain-accuracy=0.886406\n",
      "2016-10-31 00:21:30,747 Epoch[27] Batch [350]\tSpeed: 3301.88 samples/sec\tTrain-accuracy=0.888906\n",
      "2016-10-31 00:21:32,342 Epoch[27] Resetting Data Iterator\n",
      "2016-10-31 00:21:32,343 Epoch[27] Time cost=15.129\n",
      "2016-10-31 00:21:33,511 Epoch[27] Validation-accuracy=0.837223\n",
      "2016-10-31 00:21:35,396 Epoch[28] Batch [50]\tSpeed: 3429.25 samples/sec\tTrain-accuracy=0.893594\n",
      "2016-10-31 00:21:37,304 Epoch[28] Batch [100]\tSpeed: 3356.03 samples/sec\tTrain-accuracy=0.892500\n",
      "2016-10-31 00:21:39,235 Epoch[28] Batch [150]\tSpeed: 3316.86 samples/sec\tTrain-accuracy=0.893437\n",
      "2016-10-31 00:21:41,182 Epoch[28] Batch [200]\tSpeed: 3288.10 samples/sec\tTrain-accuracy=0.890469\n",
      "2016-10-31 00:21:43,126 Epoch[28] Batch [250]\tSpeed: 3294.04 samples/sec\tTrain-accuracy=0.888125\n",
      "2016-10-31 00:21:45,067 Epoch[28] Batch [300]\tSpeed: 3300.63 samples/sec\tTrain-accuracy=0.892500\n",
      "2016-10-31 00:21:47,009 Epoch[28] Batch [350]\tSpeed: 3297.73 samples/sec\tTrain-accuracy=0.893594\n",
      "2016-10-31 00:21:48,605 Epoch[28] Resetting Data Iterator\n",
      "2016-10-31 00:21:48,606 Epoch[28] Time cost=15.095\n",
      "2016-10-31 00:21:49,785 Epoch[28] Validation-accuracy=0.840684\n",
      "2016-10-31 00:21:51,687 Epoch[29] Batch [50]\tSpeed: 3399.99 samples/sec\tTrain-accuracy=0.893125\n",
      "2016-10-31 00:21:53,603 Epoch[29] Batch [100]\tSpeed: 3343.16 samples/sec\tTrain-accuracy=0.891094\n",
      "2016-10-31 00:21:55,513 Epoch[29] Batch [150]\tSpeed: 3353.48 samples/sec\tTrain-accuracy=0.890938\n",
      "2016-10-31 00:21:57,438 Epoch[29] Batch [200]\tSpeed: 3326.36 samples/sec\tTrain-accuracy=0.890312\n",
      "2016-10-31 00:21:59,372 Epoch[29] Batch [250]\tSpeed: 3311.75 samples/sec\tTrain-accuracy=0.896719\n",
      "2016-10-31 00:22:01,310 Epoch[29] Batch [300]\tSpeed: 3304.40 samples/sec\tTrain-accuracy=0.896250\n",
      "2016-10-31 00:22:03,248 Epoch[29] Batch [350]\tSpeed: 3303.27 samples/sec\tTrain-accuracy=0.889844\n",
      "2016-10-31 00:22:04,800 Epoch[29] Resetting Data Iterator\n",
      "2016-10-31 00:22:04,806 Epoch[29] Time cost=15.020\n",
      "2016-10-31 00:22:04,892 Saved checkpoint to \"model/net1-0030.params\"\n",
      "2016-10-31 00:22:06,042 Epoch[29] Validation-accuracy=0.845728\n"
     ]
    }
   ],
   "source": [
    "network = get_net()\n",
    "\n",
    "################################################################################\n",
    "# TODO: this is similar as solver                                              #\n",
    "################################################################################\n",
    "\n",
    "############################ set hyperparameters ###############################\n",
    "batch_size = 128\n",
    "weight_decay = 1e-3   # same as weight reg\n",
    "num_epoch = 30\n",
    "learning_rate = 5e-3 \n",
    "devs=mx.gpu(3)     # set device id\n",
    "\n",
    "################################  path #########################################\n",
    "data_dir = 'cifar10/'\n",
    "chk_dir = 'model/'\n",
    "chk_prefix = chk_dir +'net1'\n",
    "load_model = False   ## set true if you want to load a pretrained model and finetune with lower learning rate\n",
    "\n",
    "if not os.path.isdir(chk_dir):\n",
    "     os.system(\"mkdir \" + chk_dir)\n",
    "\n",
    "reload(logging)\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "eval_metrics = ['accuracy']\n",
    "\n",
    "## TopKAccuracy only allows top_k > 1\n",
    "#eval_metrics.append(mx.metric.create('top_k_accuracy', top_k = 5))\n",
    "\n",
    "if load_model:\n",
    "    model_prefix = 'model/net1'\n",
    "    model_iter = 30  # which model to load\n",
    "\n",
    "    _, arg_params,__ = mx.model.load_checkpoint(model_prefix, model_iter)\n",
    "else:\n",
    "    arg_params = None\n",
    "    model_iter = 0\n",
    "\n",
    "model=mx.model.FeedForward(\n",
    "       ctx      = devs,\n",
    "       symbol   = network,\n",
    "       arg_params = arg_params,\n",
    "       begin_epoch = model_iter,\n",
    "       num_epoch  = num_epoch,\n",
    "       learning_rate = learning_rate,\n",
    "       momentum      = 0.9,\n",
    "       wd            = weight_decay,\n",
    "      initializer   = mx.init.Xavier(factor_type='in', magnitude=2.34)    ## weight initialization\n",
    "       )\n",
    "\n",
    "train_ite, val_ite = get_iterator()\n",
    "model.fit(\n",
    "        X          = train_ite,\n",
    "        eval_data  = val_ite,\n",
    "        eval_metric = eval_metrics,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 50), \n",
    "        epoch_end_callback=mx.callback.do_checkpoint(chk_prefix, 10)   ## save your model after each 10 epochs\n",
    "        )\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
